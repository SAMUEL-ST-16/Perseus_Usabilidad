# ========== API Configuration ==========
HOST=0.0.0.0
PORT=8000
RELOAD=false
WORKERS=4
LOG_LEVEL=INFO

# ========== Model Configuration ==========
# HuggingFace Models (públicos)
BINARY_MODEL_NAME=SamuelSoto7/Perseus_binario
MULTICLASS_MODEL_NAME=SamuelSoto7/Perseus_Multiclase

# AI Provider Configuration
PROVIDER=groq  # "openai" or "groq" - Provider preferido para generación de descripciones

# ========== API Tokens ==========
# HuggingFace Token (obtener en https://huggingface.co/settings/tokens)
HUGGINGFACE_TOKEN=your_huggingface_token_here

# OpenAI Token (obtener en https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# Groq Token (obtener en https://console.groq.com/keys)
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxx
GROQ_MODEL_NAME=llama-3.1-8b-instant  # Modelo de Groq a utilizar

# ========== Cache Configuration ==========
ENABLE_CACHE=true
CACHE_TTL=3600

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Cache TTL Configuration (in seconds)
CACHE_TTL_LLM=604800       # 7 days for LLM descriptions
CACHE_TTL_SCRAPING=43200   # 12 hours for Play Store scraping
CACHE_TTL_ML=86400          # 24 hours for ML predictions

# ========== File Upload Configuration ==========
MAX_UPLOAD_SIZE=10485760

# ========== Scraping Configuration ==========
SCRAPER_MAX_COMMENTS=100
SCRAPER_TIMEOUT=30
